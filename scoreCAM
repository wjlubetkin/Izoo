import tensorflow as tf
import numpy as np
import matplotlib.pyplot as plt
import cv2
import os
from pathlib import Path
import seaborn as sns
from tensorflow.keras.preprocessing import image
from tensorflow.keras.applications.imagenet_utils import preprocess_input
import warnings
warnings.filterwarnings('ignore')

# Set up matplotlib for better visualization
plt.rcParams['figure.figsize'] = (15, 10)
plt.rcParams['font.size'] = 12

class ScoreCAM:
    """
    ScoreCAM implementation for visualizing model attention
    """
    def __init__(self, model, layer_name=None):
        self.model = model
        self.layer_name = layer_name
        
        # Find the last convolutional layer if not specified
        if layer_name is None:
            for layer in reversed(model.layers):
                if hasattr(layer, 'output_shape') and len(layer.output_shape) == 4:  # Conv layer has 4D output
                    self.layer_name = layer.name
                    break
                elif hasattr(layer, 'output') and len(layer.output.shape) == 4:  # Alternative check
                    self.layer_name = layer.name
                    break
        
        # Create a model that outputs the feature maps
        self.feature_model = tf.keras.Model(
            inputs=model.input,
            outputs=model.get_layer(self.layer_name).output
        )
        
        print(f"Using layer: {self.layer_name}")
        print(f"Feature map shape: {self.feature_model.output.shape}")
    
    def generate_cam(self, input_image, class_idx=None):
        """
        Generate ScoreCAM for a given input image
        """
        # Get original predictions
        original_score = self.model.predict(input_image, verbose=0)
        if class_idx is None:
            class_idx = np.argmax(original_score)
        
        # Get feature maps
        feature_maps = self.feature_model.predict(input_image, verbose=0)
        
        # Get dimensions
        batch_size, height, width, num_channels = feature_maps.shape
        input_height, input_width = input_image.shape[1], input_image.shape[2]
        
        # Initialize CAM
        cam = np.zeros((height, width), dtype=np.float32)
        
        # Process each feature map
        for i in range(num_channels):
            # Get single feature map
            feature_map = feature_maps[0, :, :, i]
            
            # Normalize feature map
            if np.max(feature_map) > np.min(feature_map):
                feature_map = (feature_map - np.min(feature_map)) / (np.max(feature_map) - np.min(feature_map))
            
            # Resize to input dimensions
            mask = cv2.resize(feature_map, (input_width, input_height))
            mask = np.expand_dims(mask, axis=-1)
            
            # Apply mask to input image
            masked_input = input_image * mask
            
            # Get prediction for masked input
            masked_score = self.model.predict(masked_input, verbose=0)
            
            # Calculate importance score
            score = masked_score[0, class_idx]
            
            # Weight the feature map by its importance
            cam += score * feature_map
        
        # Normalize CAM
        if np.max(cam) > np.min(cam):
            cam = (cam - np.min(cam)) / (np.max(cam) - np.min(cam))
        
        # Resize CAM to input dimensions
        cam_resized = cv2.resize(cam, (input_width, input_height))
        
        return cam_resized, class_idx, original_score[0, class_idx]

def load_model_and_classes(model_path, classes_path):
    """
    Load the trained model and class names
    """
    print("Loading model...")
    model = tf.keras.models.load_model(model_path)
    print(f"Model loaded successfully. Input shape: {model.input.shape}")
    
    print("Loading class names...")
    with open(classes_path, 'r') as f:
        class_names = [line.strip() for line in f.readlines()]
    print(f"Found {len(class_names)} classes: {class_names}")
    
    return model, class_names

def get_sample_images(image_dir, class_names, num_samples=1):
    """
    Get sample images from each class directory
    """
    sample_images = {}
    
    for class_name in class_names:
        class_dir = os.path.join(image_dir, class_name)
        if os.path.exists(class_dir):
            image_files = [f for f in os.listdir(class_dir) 
                          if f.lower().endswith(('.png', '.jpg', '.jpeg'))]
            
            if image_files:
                # Take the first few images as samples
                samples = image_files[:num_samples]
                sample_images[class_name] = [os.path.join(class_dir, img) for img in samples]
                print(f"Found {len(image_files)} images for class '{class_name}', using {len(samples)} samples")
            else:
                print(f"No images found for class '{class_name}'")
        else:
            print(f"Directory not found for class '{class_name}': {class_dir}")
    
    return sample_images

def preprocess_image(img_path, target_size=(224, 224)):
    """
    Load and preprocess an image for the model
    """
    img = image.load_img(img_path, target_size=target_size)
    img_array = image.img_to_array(img)
    img_array = np.expand_dims(img_array, axis=0)
    img_array = preprocess_input(img_array)
    return img_array, img

def visualize_scorecam(original_img, cam, title, prediction_score, predicted_class):
    """
    Visualize the original image and ScoreCAM heatmap
    """
    fig, axes = plt.subplots(1, 3, figsize=(15, 5))
    
    # Original image
    axes[0].imshow(original_img)
    axes[0].set_title(f'Original Image\n{title}')
    axes[0].axis('off')
    
    # CAM heatmap
    im1 = axes[1].imshow(cam, cmap='jet', alpha=0.8)
    axes[1].set_title(f'ScoreCAM Heatmap\nScore: {prediction_score:.3f}')
    axes[1].axis('off')
    plt.colorbar(im1, ax=axes[1], fraction=0.046, pad=0.04)
    
    # Overlay
    axes[2].imshow(original_img)
    axes[2].imshow(cam, cmap='jet', alpha=0.4)
    axes[2].set_title(f'Overlay\nPredicted: {predicted_class}')
    axes[2].axis('off')
    
    plt.tight_layout()
    plt.show()

# Main execution
def main():
    # Configuration
    MODEL_PATH = '/convnext_finetuned_labelsmooth.keras'
    CLASSES_PATH = '/convnext_finetuned_labelsmooth.classes.txt'
    IMAGE_DIR = '/IndyZooFaces2'
    
    # Load model and classes
    try:
        model, class_names = load_model_and_classes(MODEL_PATH, CLASSES_PATH)
    except Exception as e:
        print(f"Error loading model or classes: {e}")
        return
    
    # Get sample images
    sample_images = get_sample_images(IMAGE_DIR, class_names, num_samples=1)
    
    if not sample_images:
        print("No sample images found!")
        return
    
    # Initialize ScoreCAM with the best layer for ConvNeXt
    # Use the last activation layer before global average pooling
    scorecam = ScoreCAM(model, layer_name='convnext_base_stage_3_block_2_identity')
    
    # Process each class
    print("\nGenerating ScoreCAM visualizations...")
    
    for class_idx, class_name in enumerate(class_names):
        if class_name not in sample_images:
            print(f"Skipping {class_name} - no images found")
            continue
        
        print(f"\nProcessing class: {class_name}")
        
        for img_path in sample_images[class_name]:
            try:
                # Preprocess image
                img_array, original_img = preprocess_image(img_path)
                
                # Generate ScoreCAM
                cam, predicted_class_idx, prediction_score = scorecam.generate_cam(img_array)
                
                # Get predicted class name
                predicted_class_name = class_names[predicted_class_idx]
                
                # Visualize results
                img_name = os.path.basename(img_path)
                title = f"{class_name} - {img_name}"
                
                visualize_scorecam(
                    original_img, 
                    cam, 
                    title, 
                    prediction_score, 
                    predicted_class_name
                )
                
                # Print prediction info
                print(f"  Image: {img_name}")
                print(f"  True class: {class_name}")
                print(f"  Predicted class: {predicted_class_name}")
                print(f"  Confidence: {prediction_score:.3f}")
                print(f"  Correct: {'✓' if predicted_class_name == class_name else '✗'}")
                
            except Exception as e:
                print(f"Error processing {img_path}: {e}")
                continue
    
    print("\nScoreCAM analysis complete!")

# Run the analysis
if __name__ == "__main__":
    main()

# Additional utility functions for further analysis

def compare_classes(model, class_names, scorecam, image_paths, target_size=(224, 224)):
    """
    Compare ScoreCAM results across multiple classes
    """
    fig, axes = plt.subplots(len(image_paths), 4, figsize=(20, 5*len(image_paths)))
    if len(image_paths) == 1:
        axes = axes.reshape(1, -1)
    
    for i, (class_name, img_path) in enumerate(image_paths.items()):
        # Preprocess image
        img_array, original_img = preprocess_image(img_path, target_size)
        
        # Generate ScoreCAM
        cam, predicted_class_idx, score = scorecam.generate_cam(img_array)
        
        # Plot results
        axes[i, 0].imshow(original_img)
        axes[i, 0].set_title(f'{class_name}\nOriginal')
        axes[i, 0].axis('off')
        
        axes[i, 1].imshow(cam, cmap='jet')
        axes[i, 1].set_title(f'ScoreCAM\nScore: {score:.3f}')
        axes[i, 1].axis('off')
        
        axes[i, 2].imshow(original_img)
        axes[i, 2].imshow(cam, cmap='jet', alpha=0.4)
        axes[i, 2].set_title(f'Overlay\nPredicted: {class_names[predicted_class_idx]}')
        axes[i, 2].axis('off')
        
        # Show prediction probabilities
        all_predictions = model.predict(img_array, verbose=0)[0]
        axes[i, 3].bar(range(len(class_names)), all_predictions)
        axes[i, 3].set_title('Prediction Probabilities')
        axes[i, 3].set_xticks(range(len(class_names)))
        axes[i, 3].set_xticklabels(class_names, rotation=45, ha='right')
        axes[i, 3].tick_params(axis='x', labelsize=8)
    
    plt.tight_layout()
    plt.show()

def analyze_feature_importance(scorecam, image_path, class_names, target_size=(224, 224)):
    """
    Detailed analysis of feature importance for a single image
    """
    img_array, original_img = preprocess_image(image_path, target_size)
    
    # Get feature maps
    feature_maps = scorecam.feature_model.predict(img_array, verbose=0)
    
    # Get original prediction
    predictions = scorecam.model.predict(img_array, verbose=0)[0]
    predicted_class_idx = np.argmax(predictions)
    
    # Analyze top feature maps
    num_channels = feature_maps.shape[-1]
    channel_importance = []
    
    print("Analyzing feature map importance...")
    for i in range(min(num_channels, 20)):  # Analyze top 20 channels
        feature_map = feature_maps[0, :, :, i]
        
        # Normalize and resize
        if np.max(feature_map) > np.min(feature_map):
            feature_map_norm = (feature_map - np.min(feature_map)) / (np.max(feature_map) - np.min(feature_map))
        else:
            feature_map_norm = feature_map
        
        mask = cv2.resize(feature_map_norm, (target_size[1], target_size[0]))
        mask = np.expand_dims(mask, axis=-1)
        
        # Apply mask and get prediction
        masked_input = img_array * mask
        masked_score = scorecam.model.predict(masked_input, verbose=0)[0, predicted_class_idx]
        
        channel_importance.append((i, masked_score, feature_map_norm))
    
    # Sort by importance
    channel_importance.sort(key=lambda x: x[1], reverse=True)
    
    # Visualize top channels
    fig, axes = plt.subplots(2, 5, figsize=(20, 8))
    axes = axes.flatten()
    
    for i in range(min(10, len(channel_importance))):
        channel_idx, importance_score, feature_map = channel_importance[i]
        
        axes[i].imshow(feature_map, cmap='jet')
        axes[i].set_title(f'Channel {channel_idx}\nImportance: {importance_score:.3f}')
        axes[i].axis('off')
    
    plt.suptitle(f'Top 10 Most Important Feature Maps\nPredicted: {class_names[predicted_class_idx]}')
    plt.tight_layout()
    plt.show()
    
    return channel_importance

print("Notebook ready! Run main() to start the ScoreCAM analysis.")
print("Use compare_classes() and analyze_feature_importance() for additional analysis.")
