"""
Chimp Face Detection + Recognition Pipeline
Combines MediaPipe face detection with ConvNeXt facial recognition
"""

from __future__ import annotations

import cv2
import mediapipe as mp
import numpy as np
import tensorflow as tf
from pathlib import Path
from typing import List, Tuple, Optional
import matplotlib.pyplot as plt
import matplotlib.patches as patches
from IPython.display import display, Image as IPImage
import warnings
warnings.filterwarnings('ignore')

# ----------------------------- CONFIGURATION ---------------------------------
# Face Detection Settings
MIN_DETECTION_CONFIDENCE = 0.3
MODEL_SELECTION = 0  # 0 for short-range (2m), 1 for full-range (5m)

# ConvNeXt Model Settings  
IMG_SIZE = (224, 224)
MODEL_PATH = Path("convnext_finetuned_labelsmooth.keras")
CLASS_NAMES_TXT = Path("convnext_finetuned_labelsmooth.classes.txt")
TOP_K = 3

# Input/Output
INPUT_DIR = Path("./chimp_groups")
OUTPUT_DIR = Path("./detected_faces")
VISUALIZATION_DIR = Path("./visualizations")

# Create output directories
OUTPUT_DIR.mkdir(exist_ok=True)
VISUALIZATION_DIR.mkdir(exist_ok=True)
# -----------------------------------------------------------------------------

class ChimpFacePipeline:
    def __init__(self):
        # Initialize MediaPipe Face Detection
        self.mp_face_detection = mp.solutions.face_detection
        self.mp_drawing = mp.solutions.drawing_utils
        self.face_detection = self.mp_face_detection.FaceDetection(
            model_selection=MODEL_SELECTION,
            min_detection_confidence=MIN_DETECTION_CONFIDENCE
        )
        
        # Load ConvNeXt model
        self.convnext_model = tf.keras.models.load_model(MODEL_PATH, compile=False)
        self.num_classes = self.convnext_model.output_shape[-1]
        self.class_names = self._load_class_names()
        
    def _load_class_names(self) -> List[str]:
        """Load class names from file or generate defaults."""
        if CLASS_NAMES_TXT.exists():
            names = [line.strip() for line in CLASS_NAMES_TXT.read_text().splitlines() if line.strip()]
            if len(names) != self.num_classes:
                raise ValueError(f"Class count mismatch: {len(names)} vs {self.num_classes}")
            return names
        return [f"chimp_{i}" for i in range(self.num_classes)]
    
    def detect_faces(self, image: np.ndarray) -> List[Tuple[int, int, int, int]]:
        """
        Detect faces in image using MediaPipe.
        Returns list of bounding boxes as (x, y, width, height).
        """
        # Convert BGR to RGB for MediaPipe
        rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        results = self.face_detection.process(rgb_image)
        
        faces = []
        if results.detections:
            h, w = image.shape[:2]
            for detection in results.detections:
                bbox = detection.location_data.relative_bounding_box
                # Convert relative coordinates to absolute pixels
                x = int(bbox.xmin * w)
                y = int(bbox.ymin * h)
                width = int(bbox.width * w)
                height = int(bbox.height * h)
                
                # Ensure coordinates are within image bounds
                x = max(0, x)
                y = max(0, y)
                width = min(width, w - x)
                height = min(height, h - y)
                
                faces.append((x, y, width, height))
        
        return faces
    
    def extract_face_crops(self, image: np.ndarray, faces: List[Tuple[int, int, int, int]]) -> List[np.ndarray]:
        """Extract and resize face crops for model input."""
        crops = []
        for x, y, w, h in faces:
            # Add some padding around the face
            padding = 0.1  # 10% padding
            pad_x = int(w * padding)
            pad_y = int(h * padding)
            
            # Expand bounding box with padding
            x1 = max(0, x - pad_x)
            y1 = max(0, y - pad_y)
            x2 = min(image.shape[1], x + w + pad_x)
            y2 = min(image.shape[0], y + h + pad_y)
            
            # Extract crop
            crop = image[y1:y2, x1:x2]
            
            # Resize to model input size
            crop_resized = cv2.resize(crop, IMG_SIZE)
            crops.append(crop_resized)
            
        return crops
    
    def preprocess_for_convnext(self, crops: List[np.ndarray]) -> np.ndarray:
        """Preprocess face crops for ConvNeXt model."""
        if not crops:
            return np.array([])
        
        # Convert to float32 and keep in 0-255 range (matching your original code)
        processed = np.array(crops, dtype=np.float32)
        return processed
    
    def recognize_faces(self, face_crops: List[np.ndarray]) -> List[List[Tuple[str, float]]]:
        """Run ConvNeXt inference on face crops."""
        if not face_crops:
            return []
        
        # Preprocess crops
        input_batch = self.preprocess_for_convnext(face_crops)
        
        # Run inference
        predictions = self.convnext_model.predict(input_batch, verbose=0)
        
        # Get top-k predictions for each face
        top_k = min(TOP_K, self.num_classes)
        rank = np.argsort(-predictions, axis=1)[:, :top_k]
        
        results = []
        for i in range(len(face_crops)):
            preds = [(self.class_names[idx], float(predictions[i, idx])) for idx in rank[i]]
            results.append(preds)
        
        return results
    
    def visualize_results(self, image: np.ndarray, faces: List[Tuple[int, int, int, int]], 
                         predictions: List[List[Tuple[str, float]]], filename: str, show_inline: bool = True):
        """Create visualization with detected faces and predictions."""
        fig, ax = plt.subplots(1, 1, figsize=(12, 8))
        
        # Display image (convert BGR to RGB for matplotlib)
        rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        ax.imshow(rgb_image)
        
        # Draw bounding boxes and labels
        for i, ((x, y, w, h), preds) in enumerate(zip(faces, predictions)):
            # Draw bounding box
            rect = patches.Rectangle((x, y), w, h, linewidth=2, 
                                   edgecolor='red', facecolor='none')
            ax.add_patch(rect)
            
            # Add prediction label
            if preds:
                best_class, best_prob = preds[0]
                label = f"{i+1}: {best_class} ({best_prob:.1%})"
                ax.text(x, y-10, label, fontsize=10, 
                       bbox=dict(boxstyle="round,pad=0.3", facecolor="yellow", alpha=0.7))
        
        ax.set_title(f"Detected Faces: {filename}")
        ax.axis('off')
        
        # Save visualization
        output_path = VISUALIZATION_DIR / f"{Path(filename).stem}_detected.png"
        plt.savefig(output_path, dpi=150, bbox_inches='tight')
        
        # Show inline in notebook if requested
        if show_inline:
            plt.show()
        else:
            plt.close()
        
        return output_path
    
    def process_image(self, image_path: Path, show_visualization: bool = True) -> dict:
        """Process a single image through the complete pipeline."""
        # Load image
        image = cv2.imread(str(image_path))
        if image is None:
            raise ValueError(f"Could not load image: {image_path}")
        
        print(f"Processing {image_path.name}...")
        
        # Detect faces
        faces = self.detect_faces(image)
        print(f"  Found {len(faces)} faces")
        
        if not faces:
            return {
                'filename': image_path.name,
                'faces_detected': 0,
                'predictions': [],
                'visualization_path': None
            }
        
        # Extract face crops
        face_crops = self.extract_face_crops(image, faces)
        
        # Save individual face crops
        crop_paths = []
        for i, crop in enumerate(face_crops):
            crop_filename = f"{image_path.stem}_face_{i:02d}.jpg"
            crop_path = OUTPUT_DIR / crop_filename
            cv2.imwrite(str(crop_path), crop)
            crop_paths.append(crop_path)
        
        # Run facial recognition
        predictions = self.recognize_faces(face_crops)
        
        # Create visualization
        viz_path = self.visualize_results(image, faces, predictions, image_path.name, 
                                        show_inline=show_visualization)
        
        # Print results
        print(f"  Predictions:")
        for i, preds in enumerate(predictions):
            if preds:
                best_class, best_prob = preds[0]
                print(f"    Face {i+1}: {best_class} ({best_prob:.1%})")
        
        return {
            'filename': image_path.name,
            'faces_detected': len(faces),
            'face_crops_saved': crop_paths,
            'predictions': predictions,
            'visualization_path': viz_path
        }
    
    def process_directory(self, input_dir: Path) -> List[dict]:
        """Process all images in directory."""
        # Find all image files
        img_extensions = {'.jpg', '.jpeg', '.png', '.bmp', '.tiff'}
        image_files = [f for f in input_dir.rglob("*") 
                      if f.suffix.lower() in img_extensions]
        
        if not image_files:
            print(f"No images found in {input_dir}")
            return []
        
        print(f"Found {len(image_files)} images to process")
        
        results = []
        for image_path in sorted(image_files):
            try:
                result = self.process_image(image_path)
                results.append(result)
            except Exception as e:
                print(f"Error processing {image_path.name}: {e}")
                continue
        
        return results

# Main execution
if __name__ == "__main__":
    # Initialize pipeline
    pipeline = ChimpFacePipeline()
    
    # Process all images
    results = pipeline.process_directory(INPUT_DIR)
    
    # Summary
    total_faces = sum(r['faces_detected'] for r in results)
    processed_images = len([r for r in results if r['faces_detected'] > 0])
    
    print(f"\n=== SUMMARY ===")
    print(f"Images processed: {len(results)}")
    print(f"Images with faces: {processed_images}")
    print(f"Total faces detected: {total_faces}")
    print(f"Face crops saved to: {OUTPUT_DIR}")
    print(f"Visualizations saved to: {VISUALIZATION_DIR}")
